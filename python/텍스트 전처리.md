# 텍스트 전처리

## 1) 토큰화

얻어낸 데이터가 필요에 맞게 전처리 되지 않은 상태일 때 , 사용하고자하는 용도에 맞게

토큰화(tokenization), 정제(cleaning), 정규화(nomalization)하는 일을 해야함

** 여기서 토큰화란, 주어진 말뭉치를 토큰(token)이라는 단위로 나누는 작업을 말함.

토큰 단위는 상황에 따라 다르지만, 보통 의미있는 단위로 토큰을 정의



### 단어 토큰화 (word tokenization)

- 토큰의 기준을 단어(word)로 하는 경우 단어 토큰화라 함
- 여기서 단어(word)는 단어 단위 외에도 단어구, 의미를 갖는 문자열로도 간주되기도 함
- 구두점(punctuation)을 제거시키는 작업이 필요

여기서, 영어는 띄어쓰기로 구분하기 쉬운데, 한글을 구분하기가 어렵다.

이유는 영어는 띄어쓰기가 정확하게 들어가 있어야 해석이 되는데

한글은 띄어쓰기가 없어도 의미가 해석이 가능함에 있다

ex ) hi my name is ahn  -> himynameisahn,  안녕 나의 이름은 안이야 -> 안녕나의이름은안이야

```python
import nltk  
from nltk.tokenize import WordPunctTokenizer 
# 단어 토큰화 함수
```

-- 단어 토큰화에서 고려해야할 점

1. 구두점이나 특수 문자를 단순 제외해선 안된다.

- 구두점 조차도 하나의 토큰으로 분류할 경우가 생긴다. 

ex) 온점(.)같은경우는 문장을 구분해주는 역할을 해 문장의 경계를 알 수 있는데 도움을 줌

- 단어 자체에 구두점이 있는 경우

ex) m.p.h, Ph.D, AT&T 등

2. 줄임말과 단어 내에 띄어쓰기가 있는 경우

- 영어권에서 많이 발생함, 아포스트로피(`)

ex) i am -> i`m ,  we are -> we're 등등

### 문장 토큰화

- 토큰의 단위를 문장(sentence)으로 정함
- 보통 온점(.) 단위로 구분

```python
import nltk
from nltk.tokenize import sent_tokenize ## 이걸 사용하면 가능
```

Okt(Open Korea Text), 메캅(Mecab), 코모란(Komoran), 한나눔(Hannanum), 꼬꼬마(Kkma) 은 

konlp패키지의 한국어 분석도구

